dataset:
  root_dir: "/home/aswath/Projects/capstone/multimodel_lipread/data/GLips_4"
  cue_root: "/home/aswath/Projects/capstone/multimodel_lipread/data/GLips_4"
  lip_regions_root: "/home/aswath/Projects/capstone/multimodel_lipread/data/GLips_4_lip_regions"
  cache_dir: "/home/aswath/Projects/capstone/multimodel_lipread/audio_cues_video/.cache_cues"
  embed_model: "sentence-transformers/all-mpnet-base-v2"
  input_size: 117
  split: "train"
  cue_mode: "emotion"
  num_classes: 4

train:
  batch: 4
  lr: 0.00001
  epochs: 5
  workers: 4
  model_name: "late_fusion_mobile" #early_fusion_mobile, middle_fusion_mobile, late_fusion_mobile, early_fusion_resnet, middle_fusion_resnet, late_fusion_resnet
  metrics_dir: "/home/aswath/Projects/capstone/multimodel_lipread/audio_cues_video/metrics"
  save_dir: "/home/aswath/Projects/capstone/multimodel_lipread/audio_cues_video/models_trained"  

# video_model_config:
#   model:
#     feature_dim: 256
#     dropout: 0.3